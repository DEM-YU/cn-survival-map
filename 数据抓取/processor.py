"""
Data Processor: Raw Prices ‚Üí Purchasing Power Index
=====================================================
1. Normalize all product prices to "per 500g (1Êñ§)"
2. Calculate a "Survival Basket" cost per city/province
3. Compute Purchasing Power Index = Hourly Wage / Basket Cost
4. Output rpp_final.json for the frontend map

Usage:
    python processor.py                # Process raw_supermarket_data.json
    python processor.py --generate     # Generate full 31-province output from wage data
"""

import json
import re
import sys
from pathlib import Path

# ---------------------------------------------------------------------------
# Price normalizer
# ---------------------------------------------------------------------------
def normalize_price(price: float, title: str) -> float | None:
    """
    Extract weight/volume from product title and convert price to per-500g.

    Supported patterns:
        - "10kg", "5kg", "2.5kg"  ‚Üí weight in grams
        - "500g", "250g"          ‚Üí direct grams
        - "5L", "1.8L", "900ml"  ‚Üí volume (1L ‚âà 1000g for liquids)
        - "10Êñ§", "5Êñ§"           ‚Üí 1Êñ§ = 500g
        - "250ml*24", "250ml*12" ‚Üí total volume = per_unit * count

    Returns price per 500g, or None if unparsable.
    """
    if price <= 0:
        return None

    # --- Handle "Xml*N" patterns first (e.g., "250ml*24") ---
    multi_match = re.search(
        r"(\d+(?:\.\d+)?)\s*(ml|ML)\s*[*√óxX]\s*(\d+)", title
    )
    if multi_match:
        per_unit_ml = float(multi_match.group(1))
        count = int(multi_match.group(3))
        total_grams = per_unit_ml * count  # ml ‚âà g for milk/liquids
        if total_grams > 0:
            return round(price / total_grams * 500, 2)

    # --- Handle "N*Xml" patterns (e.g., "12*250ml") ---
    multi_match2 = re.search(
        r"(\d+)\s*[*√óxX]\s*(\d+(?:\.\d+)?)\s*(ml|ML)", title
    )
    if multi_match2:
        count = int(multi_match2.group(1))
        per_unit_ml = float(multi_match2.group(2))
        total_grams = per_unit_ml * count
        if total_grams > 0:
            return round(price / total_grams * 500, 2)

    # --- Standard single-unit patterns ---
    match = re.search(
        r"(\d+(?:\.\d+)?)\s*(kg|KG|g|G|ml|ML|L|Êñ§|jin)", title, re.IGNORECASE
    )
    if not match:
        return None

    value = float(match.group(1))
    unit = match.group(2).lower()

    # Convert to grams
    if unit in ("kg",):
        grams = value * 1000
    elif unit in ("g",):
        grams = value
    elif unit in ("l",):
        grams = value * 1000  # 1L ‚âà 1000g
    elif unit in ("ml",):
        grams = value
    elif unit in ("Êñ§", "jin"):
        grams = value * 500
    else:
        return None

    if grams <= 0:
        return None

    return round(price / grams * 500, 2)


# ---------------------------------------------------------------------------
# Basket calculator
# ---------------------------------------------------------------------------
BASKET_WEIGHTS = {
    "‰∫îËä±ËÇâ": 1.0,      # 1 √ó 500g of pork
    "Êï£Ë£ÖÈ∏°Ëõã": 1.0,    # 1 √ó 500g of eggs
    "‰∏úÂåóÂ§ßÁ±≥": 1.0,     # 1 √ó 500g of rice
    "ÈáëÈæôÈ±ºÂ§ßË±ÜÊ≤π": 0.5, # 0.5 √ó 500g of oil
    "Á∫ØÁâõÂ•∂": 1.0,       # 1 √ó 500g of milk
}


def calculate_basket(city_data: list[dict]) -> float | None:
    """
    Calculate the cost of a "Survival Basket" for a city.
    Uses the median normalized price for each category.
    """
    category_prices: dict[str, list[float]] = {}

    for item in city_data:
        keyword = item["keyword"]
        norm = normalize_price(item["price"], item["product_name"] + " " + item.get("unit", ""))
        if norm is not None and norm > 0:
            category_prices.setdefault(keyword, []).append(norm)

    basket_cost = 0.0
    for keyword, weight in BASKET_WEIGHTS.items():
        prices = category_prices.get(keyword, [])
        if not prices:
            # Use a reasonable default if category is missing
            defaults = {"‰∫îËä±ËÇâ": 15, "Êï£Ë£ÖÈ∏°Ëõã": 6, "‰∏úÂåóÂ§ßÁ±≥": 3, "ÈáëÈæôÈ±ºÂ§ßË±ÜÊ≤π": 6, "Á∫ØÁâõÂ•∂": 5}
            median_price = defaults.get(keyword, 10)
        else:
            prices.sort()
            mid = len(prices) // 2
            median_price = prices[mid]
        basket_cost += median_price * weight

    return round(basket_cost, 2)


# ---------------------------------------------------------------------------
# Province wage data (Minimum Hourly Wage, ¬•/hr, 2024 standards)
# ---------------------------------------------------------------------------
PROVINCE_WAGES = {
    "Âåó‰∫¨": 26, "Â§©Ê¥•": 22, "‰∏äÊµ∑": 24, "ÈáçÂ∫Ü": 21,
    "Ê≤≥Âåó": 19, "Â±±Ë•ø": 18, "ËæΩÂÆÅ": 19, "ÂêâÊûó": 18,
    "ÈªëÈæôÊ±ü": 18, "Ê±üËãè": 22, "ÊµôÊ±ü": 23, "ÂÆâÂæΩ": 19,
    "Á¶èÂª∫": 21, "Ê±üË•ø": 18, "Â±±‰∏ú": 20, "Ê≤≥Âçó": 18,
    "ÊπñÂåó": 20, "ÊπñÂçó": 19, "Âπø‰∏ú": 22, "Êµ∑Âçó": 19,
    "ÂõõÂ∑ù": 21, "Ë¥µÂ∑û": 18, "‰∫ëÂçó": 18, "Ë•øËóè": 19,
    "ÈôïË•ø": 19, "ÁîòËÇÉ": 17, "ÈùíÊµ∑": 18, "ÂÆÅÂ§è": 18,
    "Êñ∞ÁñÜ": 19, "ÂÜÖËíôÂè§": 19, "ÂπøË•ø": 18,
}

# City ‚Üí Province mapping for scraper data
CITY_TO_PROVINCE = {
    "Ê≤àÈò≥": "ËæΩÂÆÅ",
    "‰∏äÊµ∑": "‰∏äÊµ∑",
    "ÊàêÈÉΩ": "ÂõõÂ∑ù",
    "Ê∑±Âú≥": "Âπø‰∏ú",
}

# Realistic basket price estimates for all 31 provinces (¬• per basket)
# Used when scraper data is unavailable for a province
PROVINCE_BASKET_ESTIMATES = {
    "Âåó‰∫¨": 20.5, "Â§©Ê¥•": 17.8, "‰∏äÊµ∑": 19.2, "ÈáçÂ∫Ü": 16.5,
    "Ê≤≥Âåó": 14.5, "Â±±Ë•ø": 14.2, "ËæΩÂÆÅ": 13.0, "ÂêâÊûó": 12.5,
    "ÈªëÈæôÊ±ü": 12.0, "Ê±üËãè": 16.0, "ÊµôÊ±ü": 17.5, "ÂÆâÂæΩ": 14.0,
    "Á¶èÂª∫": 16.8, "Ê±üË•ø": 15.0, "Â±±‰∏ú": 14.8, "Ê≤≥Âçó": 14.5,
    "ÊπñÂåó": 15.2, "ÊπñÂçó": 15.5, "Âπø‰∏ú": 17.0, "Êµ∑Âçó": 18.5,
    "ÂõõÂ∑ù": 15.8, "Ë¥µÂ∑û": 16.0, "‰∫ëÂçó": 15.5, "Ë•øËóè": 21.0,
    "ÈôïË•ø": 15.0, "ÁîòËÇÉ": 14.0, "ÈùíÊµ∑": 17.0, "ÂÆÅÂ§è": 15.5,
    "Êñ∞ÁñÜ": 15.8, "ÂÜÖËíôÂè§": 13.5, "ÂπøË•ø": 16.2,
}


# ---------------------------------------------------------------------------
# Process scraped data into per-province results
# ---------------------------------------------------------------------------
def process_scraped_data(raw_data: list[dict]) -> dict[str, float]:
    """Group raw data by city, calculate basket, map to province."""
    city_groups: dict[str, list[dict]] = {}
    for item in raw_data:
        city_groups.setdefault(item["city"], []).append(item)

    province_baskets: dict[str, float] = {}
    for city, items in city_groups.items():
        province = CITY_TO_PROVINCE.get(city, city)
        basket = calculate_basket(items)
        if basket:
            province_baskets[province] = basket
            print(f"  üì¶ {city} ‚Üí {province}: basket = ¬•{basket}")

    return province_baskets


def generate_final_output(province_baskets: dict[str, float] | None = None) -> list[dict]:
    """Generate the final JSON for all 31 provinces."""
    results = []

    for province, wage in PROVINCE_WAGES.items():
        # Use scraped basket price if available, else use estimate
        if province_baskets and province in province_baskets:
            basket_price = province_baskets[province]
        else:
            basket_price = PROVINCE_BASKET_ESTIMATES[province]

        index = round(wage / basket_price, 2)

        results.append({
            "name": province,
            "wage": wage,
            "basket_price": basket_price,
            "index": index,
        })

    # Sort by index descending
    results.sort(key=lambda x: x["index"], reverse=True)
    return results


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------
def main():
    generate_only = "--generate" in sys.argv

    province_baskets = None

    if not generate_only:
        raw_path = Path(__file__).parent / "raw_supermarket_data.json"
        if raw_path.exists():
            print(f"üìÇ Loading raw data from {raw_path}...")
            with open(raw_path, "r", encoding="utf-8") as f:
                raw_data = json.load(f)
            print(f"   Loaded {len(raw_data)} items")

            print("\nüßÆ Normalizing prices and calculating baskets...")
            province_baskets = process_scraped_data(raw_data)
        else:
            print(f"‚ö†Ô∏è  {raw_path} not found. Using estimated data for all provinces.")

    print("\nüìä Generating final output for 31 provinces...")
    results = generate_final_output(province_baskets)

    # Output to public/data/rpp_final.json
    output_dir = Path(__file__).parent.parent / "public" / "data"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "rpp_final.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ Saved {len(results)} provinces to {output_path}")
    print("\nüìã Summary:")
    print(f"   {'Province':<8}  {'Wage':>5}  {'Basket':>7}  {'Index':>6}")
    print(f"   {'‚îÄ' * 8}  {'‚îÄ' * 5}  {'‚îÄ' * 7}  {'‚îÄ' * 6}")
    for r in results[:5]:
        print(f"   {r['name']:<8}  ¬•{r['wage']:>4}  ¬•{r['basket_price']:>6}  {r['index']:>6}")
    print(f"   ... ({len(results) - 10} more) ...")
    for r in results[-5:]:
        print(f"   {r['name']:<8}  ¬•{r['wage']:>4}  ¬•{r['basket_price']:>6}  {r['index']:>6}")


if __name__ == "__main__":
    main()
